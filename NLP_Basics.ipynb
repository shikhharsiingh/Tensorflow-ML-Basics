{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Basics.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPNCVMUX/KSYvDXCbNUcQd7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shikhharsiingh/Tensorflow-ML-Basics/blob/main/NLP_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJRK6N63KMHV"
      },
      "source": [
        "### Disaster vs Not Disaster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v2U0qgaQ8m9"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3czGqBmRW_-",
        "outputId": "2166b2c3-5a67-4bd7-be0e-9298e444af97"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-28 17:21:19--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-28 17:21:20 (77.7 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPg-vk6pRrOx",
        "outputId": "e1c9dfc6-edb3-4cc1-93a9-8093e3acfcc1"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-28 17:21:20--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.13.240, 142.251.33.208, 172.217.9.208, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.13.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2021-05-28 17:21:20 (134 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDkv7GuFYo7y"
      },
      "source": [
        "unzip_data('nlp_getting_started.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AH2hyyMxZCNu"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "7gz7DxHLZKlP",
        "outputId": "8f1c7134-f99c-4284-981f-736209cf07ae"
      },
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri7v94O0Zi6h"
      },
      "source": [
        "Shuffle Training data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bbJkwfCZfvY"
      },
      "source": [
        "train_df_shuffled = train_df.sample(frac = 1, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHPOkK8fZ4MY",
        "outputId": "c2966511-6a43-45b2-f828-6b40f59507e7"
      },
      "source": [
        "train_df_shuffled.target.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R826nwTZ_9v",
        "outputId": "7e76f6ec-15e1-4647-feb7-759ac855e8e3"
      },
      "source": [
        "import random\n",
        "rand_index = random.randint(0, len(train_df_shuffled) - 5)\n",
        "\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][rand_index : rand_index + 5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(Disaster)\\n\" if target > 0 else \"(not a disaster)\\n\")\n",
        "  print(f\"Text: {text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 0 (not a disaster)\n",
            "\n",
            "Text: By the grace of GOD I survived the 2am shift and im not that tired.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0 (not a disaster)\n",
            "\n",
            "Text: @PLlolz @Grazed @Stretcher @invalid @witter @Towel still a lot\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1 (Disaster)\n",
            "\n",
            "Text: As California fires rage the Forest Service sounds the alarm about rising wildfire costs http://t.co/Tft1bb4xaZ\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1 (Disaster)\n",
            "\n",
            "Text: @colinhoffman29 I hope he does. And I hope you die in the explosion too\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1 (Disaster)\n",
            "\n",
            "Text: Scene of the derailment.. CTA Green Line at 63rd/Prairie http://t.co/zz5UDiLrea\n",
            "\n",
            "----\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ45JTQ_b5lw"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ByRrO9QcQIh"
      },
      "source": [
        "train_st, val_st, train_lab, val_lab = train_test_split(train_df_shuffled[\"text\"].to_numpy(), \n",
        "                                                        train_df_shuffled[\"target\"].to_numpy(), \n",
        "                                                        test_size = 0.1, \n",
        "                                                        random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWctkMBBdWoA"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y5g51_MKY9L"
      },
      "source": [
        "Text Vectorization basics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LbYAkgBi4BR"
      },
      "source": [
        "text_vectorizer = TextVectorization(max_tokens = None,\n",
        "                                    standardize = \"lower_and_strip_punctuation\",\n",
        "                                    split = \"whitespace\",\n",
        "                                    ngrams = None,\n",
        "                                    output_mode = 'int',\n",
        "                                    output_sequence_length = None,\n",
        "                                    pad_to_max_tokens = True\n",
        "                                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8PWN7oqjdau",
        "outputId": "c33aaab1-73cc-4e6f-aae5-77f73f7811e6"
      },
      "source": [
        "round(sum([len(i.split()) for i in train_st]) / len(train_st))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAfeR0nVkDdc"
      },
      "source": [
        "max_vocab_length = 10000\n",
        "max_length = 15\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens = max_vocab_length,\n",
        "                                   output_mode = 'int',\n",
        "                                   output_sequence_length = max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPluZ5whkqZP"
      },
      "source": [
        "#Learning Vocabulary\n",
        "text_vectorizer.adapt(train_st) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqmW8RiElSOf",
        "outputId": "d75aedb7-f972-4464-fa00-7558b5717ab8"
      },
      "source": [
        "sample_st = \"There's a flood in my town!\"\n",
        "text_vectorizer([sample_st])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 801,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8RCYMNyldky",
        "outputId": "d3a5e057-173b-4a94-d262-390d38bb93ef"
      },
      "source": [
        "rand_st = random.choice(train_st)\n",
        "\n",
        "print(f\"Original text : {rand_st} \\n\\n Vectorised version: \")\n",
        "text_vectorizer([rand_st])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text : @realhotcullen I agree but I knew we'd be going to the deep roads again because they found Blight in red lyrium. It ain't over yet &gt;_&gt; \n",
            "\n",
            " Vectorised version: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[9314,    8, 1331,   30,    8, 1826, 1924,   21,  104,    5,    2,\n",
              "        1088, 1774,  282,  152]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJnFeja6nUTZ",
        "outputId": "937c1c88-c69c-4759-b6df-5614f9339bb2"
      },
      "source": [
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[ :5]\n",
        "bottom_5_words = words_in_vocab[-5 : ]\n",
        "print(top_5_words, bottom_5_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '[UNK]', 'the', 'a', 'in'] ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi5C-iOGnzf8"
      },
      "source": [
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPKiAxPQNztL",
        "outputId": "74f39776-9b90-4761-9789-31026657b8d6"
      },
      "source": [
        "#Embedding Layers sample\n",
        "embedding = layers.Embedding(input_dim = max_vocab_length,\n",
        "                             output_dim = 128, #usually better if the number is divisible by 8\n",
        "                             input_length = max_length\n",
        "                             )\n",
        "\n",
        "embedding\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7f743051ff10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15Y3YvLcOVoP",
        "outputId": "0f266173-99e3-45d0-9c09-e960ce4b00f7"
      },
      "source": [
        "rand_st = random.choice(train_st)\n",
        "\n",
        "print(f\"Original sentence : {rand_st} \\n\\n\")\n",
        "embed = embedding(text_vectorizer([rand_st]))\n",
        "embed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original sentence : @HfxStanfield @beelieveDC @DiscoveryCntr what is happening we hear there is runway lighting damage by a contractor. \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.03279951,  0.03561572, -0.04232747, ...,  0.02692059,\n",
              "          0.02539798,  0.03426269],\n",
              "        [ 0.03279951,  0.03561572, -0.04232747, ...,  0.02692059,\n",
              "          0.02539798,  0.03426269],\n",
              "        [ 0.03279951,  0.03561572, -0.04232747, ...,  0.02692059,\n",
              "          0.02539798,  0.03426269],\n",
              "        ...,\n",
              "        [-0.03245721, -0.046459  ,  0.00887945, ..., -0.03530528,\n",
              "         -0.04417102,  0.03688164],\n",
              "        [-0.0177898 ,  0.04793732, -0.02897788, ...,  0.02928397,\n",
              "          0.03570917, -0.03229103],\n",
              "        [-0.02997971, -0.04162784,  0.02729831, ...,  0.00966929,\n",
              "          0.02576122,  0.02535724]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8BBfGcMmEw_",
        "outputId": "e815f8ac-f984-452b-df2f-e5e2c7df2a8f"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()),\n",
        "                    (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "model_0.fit(train_st, train_lab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdSQXxTQnQrW",
        "outputId": "d79abbeb-999e-4f07-a1ef-078f23e11522"
      },
      "source": [
        "baseline_score = model_0.score(val_st, val_lab)\n",
        "print(f\"{baseline_score * 100:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa2uYiagq_HX",
        "outputId": "d30aa1a0-5486-4536-ae01-1b67a2dfb3c9"
      },
      "source": [
        "baseline_preds = model_0.predict(val_st)\n",
        "\n",
        "baseline_preds[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5jreYZ0n6Xy",
        "outputId": "d247b503-1d64-4ade-f413-cd053476861c"
      },
      "source": [
        "train_df.text.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11-Year-Old Boy Charged With Manslaughter of Toddler: Report: An 11-year-old boy has been charged with manslaughter over the fatal sh...        10\n",
              "#Bestnaijamade: 16yr old PKK suicide bomber who detonated bomb in ... http://t.co/KSAwlYuX02 bestnaijamade bestnaijamade bestnaijamade beÛ_     6\n",
              "The Prophet (peace be upon him) said 'Save yourself from Hellfire even if it is by giving half a date in charity.'                               6\n",
              "He came to a land which was engulfed in tribal war and turned it into a land of peace i.e. Madinah. #ProphetMuhammad #islam                      6\n",
              "Madhya Pradesh Train Derailment: Village Youth Saved Many Lives                                                                                  5\n",
              "                                                                                                                                                ..\n",
              "./.....hmm 12000 Nigerian refugees repatriated from Cameroon http://t.co/96p3hUJNTj /(                                                           1\n",
              "#news Madhya Pradesh Train Derailment: Village Youth Saved Many Lives http://t.co/fcTrAWJcYL #til_now #NDTV                                      1\n",
              "Method in contemplation of incident an leading bridal landslide: wiWNpFXA http://t.co/xysNXUM29T                                                 1\n",
              "The Fake of Nanking Massacre-4 Eyewitnesses (English): http://t.co/TiPnDEmPuz  #Obama #Clinton #Bush #GOP #ABC #CBS #BBC #CNN #WSJ #WPO          1\n",
              "Another White mass murderer. Thank God I'm from California. @FrauTrapani                                                                         1\n",
              "Name: text, Length: 7503, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bgqi_osAonj6"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_result(y_true, y_pred):\n",
        "\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average = \"weighted\")\n",
        "  model_results = {\"accuracy\" : model_accuracy,\n",
        "                  \"precision\" : model_precision,\n",
        "                  \"recall\" : model_recall,\n",
        "                  \"f1\" : model_f1}\n",
        "\n",
        "  return model_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtrhmwtAqXUo",
        "outputId": "ae8f71c2-f647-4dec-f88f-ff42062834b1"
      },
      "source": [
        "baseline_results = calculate_result(y_true = val_lab, y_pred = baseline_preds)\n",
        "\n",
        "baseline_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvr5tjSWrXTi"
      },
      "source": [
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV8rvkJIroQ2"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape = (1, ), dtype = tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "#x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs, name = \"model_1_dense\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H120i3kjsaCv"
      },
      "source": [
        "model_1.compile(loss = \"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj5ghnzDss6-",
        "outputId": "9fc3dbd1-5feb-42a7-fc00-9c5a7d8a95ca"
      },
      "source": [
        "model_1_history = model_1.fit(x = train_st,\n",
        "                              y = train_lab,\n",
        "                              epochs = 5,\n",
        "                              validation_data = (val_st, val_lab),\n",
        "                              callbacks = [create_tensorboard_callback(dir_name = SAVE_DIR, experiment_name = \"model_1_dense\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20210528-150634\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 16ms/step - loss: 0.1230 - accuracy: 0.9666 - val_loss: 0.5836 - val_accuracy: 0.7887\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0797 - accuracy: 0.9781 - val_loss: 0.6189 - val_accuracy: 0.7848\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.0636 - accuracy: 0.9806 - val_loss: 0.6551 - val_accuracy: 0.7835\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.0545 - accuracy: 0.9819 - val_loss: 0.6807 - val_accuracy: 0.7822\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.0488 - accuracy: 0.9825 - val_loss: 0.7137 - val_accuracy: 0.7822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-2M10RauKxG",
        "outputId": "81d5ebbc-4a08-4637-c35a-0a7ba47d66de"
      },
      "source": [
        "model_1.evaluate(val_st, val_lab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7966\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4652634561061859, 0.7965879440307617]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSy0wE_4x3rz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acdb67fb-7c9a-4373-c8e5-8e54f8d9361f"
      },
      "source": [
        "model_1_preds = model_1.predict(val_st)\n",
        "model_1_preds[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4809782 ],\n",
              "       [0.7636915 ],\n",
              "       [0.99354905],\n",
              "       [0.0470382 ],\n",
              "       [0.34432152],\n",
              "       [0.9322132 ],\n",
              "       [0.87793136],\n",
              "       [0.98590785],\n",
              "       [0.91485864],\n",
              "       [0.05842266],\n",
              "       [0.20985834],\n",
              "       [0.6477279 ],\n",
              "       [0.13078316],\n",
              "       [0.20517862],\n",
              "       [0.0243975 ],\n",
              "       [0.0209682 ],\n",
              "       [0.03014464],\n",
              "       [0.27370465],\n",
              "       [0.2795046 ],\n",
              "       [0.49062133]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mitnQV1M5OlV",
        "outputId": "238ca2c4-02d6-483b-e9b2-06f7ef9cbf0a"
      },
      "source": [
        "model_1_results = tf.squeeze(tf.round(model_1_preds))\n",
        "model_1_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2USZRLZU6EKl",
        "outputId": "21ca2578-1c17-409a-a929-d15c8bcf80be"
      },
      "source": [
        "results = calculate_result(y_true = val_lab, y_pred = model_1_results)\n",
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.65879265091863,\n",
              " 'f1': 0.7936568606792885,\n",
              " 'precision': 0.8021362275097936,\n",
              " 'recall': 0.7965879265091863}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GtXNDHGpsSp",
        "outputId": "0950e3c9-b517-41cb-f2b6-7bcd36736855"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUoNJltupY_C"
      },
      "source": [
        "#embed_weights = model_1.get_layer('embedding_1')\n",
        "#embed_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cuLNRFFG98Z"
      },
      "source": [
        "LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-mqr48Cp0Mr",
        "outputId": "342c631a-4d5d-4ab1-e793-4770150ccf35"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape = (1, ), dtype = 'string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(x.shape)\n",
        "x = layers.LSTM(64, return_sequences = True)(x)\n",
        "print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "print(x.shape)\n",
        "#x = layers.Dense(64, activation = 'relu')(x)\n",
        "#print(x.shape)\n",
        "outputs = layers.Dense(1, activation = 'sigmoid')(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name = 'model_2_LSTM')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 15, 128)\n",
            "(None, 15, 64)\n",
            "(None, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggtyXP1rgSta",
        "outputId": "5397a3d7-092b-4345-8413-d6c0c473833a"
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 15, 64)            49408     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,366,657\n",
            "Trainable params: 1,366,657\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOUQTonje8dE"
      },
      "source": [
        "model_2.compile(loss = \"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx-HnUJ-fZmi",
        "outputId": "1e8f560f-d40e-4df4-f06d-cf80ee8d65f4"
      },
      "source": [
        "model_2_history = model_2.fit(x = train_st,\n",
        "                              y = train_lab,\n",
        "                              epochs = 5,\n",
        "                              validation_data = (val_st, val_lab),\n",
        "                              callbacks = [create_tensorboard_callback(dir_name = SAVE_DIR, experiment_name = 'LSTM_training')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/LSTM_training/20210528-150519\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.0423 - accuracy: 0.9794 - val_loss: 1.2045 - val_accuracy: 0.7520\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0416 - accuracy: 0.9793 - val_loss: 1.5058 - val_accuracy: 0.7533\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0367 - accuracy: 0.9801 - val_loss: 1.5421 - val_accuracy: 0.7651\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0380 - accuracy: 0.9815 - val_loss: 1.5032 - val_accuracy: 0.7638\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0355 - accuracy: 0.9820 - val_loss: 1.7218 - val_accuracy: 0.7546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ed_P8huhFWW"
      },
      "source": [
        "inputs = layers.Input(shape = (1, ), dtype = 'string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64, return_sequences = True)(x)\n",
        "#x = layers.LSTM(64)(x)\n",
        "#x = layers.GRU(64)(x)\n",
        "#x = layers.Dense(64, activation = 'relu')(x)\n",
        "outputs = layers.Dense(1, activation = 'sigmoid')(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name = 'Model_3')\n",
        "model_3.compile(loss = 'binary_crossentropy',\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7WgGpSfjNfX",
        "outputId": "c7032dd3-2699-426f-be0a-098bcbc69a78"
      },
      "source": [
        "model_3_history = model_3.fit(x = train_st,\n",
        "                              y = train_lab,\n",
        "                              epochs = 5,\n",
        "                              validation_data = (val_st, val_lab),\n",
        "                              callbacks = [create_tensorboard_callback(dir_name = SAVE_DIR, experiment_name = 'GRU Training')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/GRU Training/20210528-151936\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 20ms/step - loss: 0.2905 - accuracy: 0.8726 - val_loss: 0.6808 - val_accuracy: 0.7381\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.2067 - accuracy: 0.9115 - val_loss: 0.7289 - val_accuracy: 0.7341\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.1846 - accuracy: 0.9189 - val_loss: 0.7959 - val_accuracy: 0.7259\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.1662 - accuracy: 0.9238 - val_loss: 0.8579 - val_accuracy: 0.7316\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.1540 - accuracy: 0.9262 - val_loss: 1.0137 - val_accuracy: 0.7223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I28p12wY_1iZ",
        "outputId": "555b4c31-add0-4396-f8de-54ba9fb466d8"
      },
      "source": [
        "inputs = layers.Input(shape = (1, ), dtype = 'string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences = True))(x)\n",
        "#x = layers.LSTM(64)(x)\n",
        "x = layers.Bidirectional(layers.GRU(64, ))(x)\n",
        "#x = layers.Dense(64, activation = 'relu')(x)\n",
        "outputs = layers.Dense(1, activation = 'sigmoid')(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name = 'Model_4')\n",
        "model_4.compile(loss = 'binary_crossentropy',\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])\n",
        "model_4.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 15, 128)           98816     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 128)               74496     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,453,441\n",
            "Trainable params: 1,453,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yrWJc_1C3vw",
        "outputId": "bec43b90-e745-419b-a430-d9bf959e552b"
      },
      "source": [
        "model_4_history = model_4.fit(x = train_st,\n",
        "                              y = train_lab,\n",
        "                              epochs = 5,\n",
        "                              validation_data = (val_st, val_lab),\n",
        "                              callbacks = [create_tensorboard_callback(dir_name = SAVE_DIR, experiment_name = 'Bidirectional Training')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/Bidirectional Training/20210528-173709\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 17s 31ms/step - loss: 0.5056 - accuracy: 0.7581 - val_loss: 0.4662 - val_accuracy: 0.7835\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.3090 - accuracy: 0.8732 - val_loss: 0.4682 - val_accuracy: 0.7677\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.2048 - accuracy: 0.9222 - val_loss: 0.5918 - val_accuracy: 0.7730\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.1323 - accuracy: 0.9558 - val_loss: 0.6667 - val_accuracy: 0.7638\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.0860 - accuracy: 0.9680 - val_loss: 0.8157 - val_accuracy: 0.7572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Puhr-6OQCn7"
      },
      "source": [
        "inputs = layers.Input(shape = (1, ), dtype = 'string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters = 64, return_sequences = True)(x)\n",
        "#x = layers.LSTM(64)(x)\n",
        "#x = layers.GRU(64)(x)\n",
        "#x = layers.Dense(64, activation = 'relu')(x)\n",
        "outputs = layers.Dense(1, activation = 'sigmoid')(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name = 'Model_3')\n",
        "model_3.compile(loss = 'binary_crossentropy',\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}